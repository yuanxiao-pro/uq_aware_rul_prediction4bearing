#!/usr/bin/env python3
"""
æµ‹è¯•ä¿®å¤åçš„Function KLè®¡ç®—ç¨³å®šæ€§
"""

import sys
sys.path.append('å‰©ä½™å¯¿å‘½é¢„æµ‹æ¨¡å‹')

import torch
import torch.nn as nn
from bayesian_torch.layers import Conv1dReparameterization, LinearReparameterization
from function_kl import get_bayesian_model_mu_rho, calculate_function_kl, ensure_positive_definite
import numpy as np

# ç®€åŒ–çš„BayesianTCNæ¨¡å‹ç”¨äºæµ‹è¯•
class SimpleBayesianModel(nn.Module):
    def __init__(self, input_dim=11, hidden_dim=64, output_dim=1):
        super().__init__(self)
        self.feature = LinearReparameterization(
            input_dim, hidden_dim,
            prior_mean=0, prior_variance=1, 
            posterior_mu_init=0, posterior_rho_init=-3
        )
        self.mu = LinearReparameterization(
            hidden_dim, output_dim,
            prior_mean=0, prior_variance=1,
            posterior_mu_init=0, posterior_rho_init=-3
        )
    
    def forward(self, x, feature=False):
        x = x.view(x.size(0), -1)
        feat, _ = self.feature(x)
        mu, _ = self.mu(feat)
        if feature:
            return mu, None, 0.0, feat
        return mu, None, 0.0
    
    def generate_init_params(self, sample_input):
        with torch.no_grad():
            _ = self.forward(sample_input)
            return {k: v.clone() for k, v in self.state_dict().items()}

def test_positive_definite_function():
    """æµ‹è¯•æ­£å®šæ€§æ£€æŸ¥å‡½æ•°"""
    print("=== æµ‹è¯•æ­£å®šæ€§æ£€æŸ¥å‡½æ•° ===")
    
    # æµ‹è¯•1: å·²ç»æ­£å®šçš„çŸ©é˜µ
    pos_def_matrix = torch.eye(3) * 2.0
    result1 = ensure_positive_definite(pos_def_matrix)
    print(f"æµ‹è¯•1 - æ­£å®šçŸ©é˜µ: è¾“å…¥ç‰¹å¾å€¼ {torch.linalg.eigvals(pos_def_matrix)}")
    print(f"         è¾“å‡ºç‰¹å¾å€¼ {torch.linalg.eigvals(result1)}")
    
    # æµ‹è¯•2: åŠæ­£å®šçŸ©é˜µï¼ˆæœ‰é›¶ç‰¹å¾å€¼ï¼‰
    semi_pos_def = torch.tensor([[1.0, 1.0], [1.0, 1.0]])
    result2 = ensure_positive_definite(semi_pos_def)
    print(f"æµ‹è¯•2 - åŠæ­£å®šçŸ©é˜µ: è¾“å…¥ç‰¹å¾å€¼ {torch.linalg.eigvals(semi_pos_def)}")
    print(f"           è¾“å‡ºç‰¹å¾å€¼ {torch.linalg.eigvals(result2)}")
    
    # æµ‹è¯•3: è´Ÿå®šçŸ©é˜µ
    neg_def = torch.tensor([[-2.0, 0.5], [0.5, -1.0]])
    result3 = ensure_positive_definite(neg_def)
    print(f"æµ‹è¯•3 - è´Ÿå®šçŸ©é˜µ: è¾“å…¥ç‰¹å¾å€¼ {torch.linalg.eigvals(neg_def)}")
    print(f"         è¾“å‡ºç‰¹å¾å€¼ {torch.linalg.eigvals(result3)}")
    
    # éªŒè¯æ‰€æœ‰ç»“æœéƒ½æ˜¯æ­£å®šçš„
    for i, result in enumerate([result1, result2, result3], 1):
        try:
            torch.linalg.cholesky(result)
            print(f"âœ“ æµ‹è¯•{i}: ä¿®å¤åçš„çŸ©é˜µæ˜¯æ­£å®šçš„")
        except:
            print(f"âœ— æµ‹è¯•{i}: ä¿®å¤åçš„çŸ©é˜µä»ç„¶ä¸æ˜¯æ­£å®šçš„")
    print()

def test_function_kl_stability():
    """æµ‹è¯•Function KLè®¡ç®—ç¨³å®šæ€§"""
    print("=== æµ‹è¯•Function KLè®¡ç®—ç¨³å®šæ€§ ===")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæµ‹è¯•æ¨¡å‹
    model = SimpleBayesianModel().to(device)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_sizes = [16, 32, 64]
    success_count = 0
    total_tests = 0
    
    for batch_size in batch_sizes:
        print(f"\næµ‹è¯•æ‰¹æ¬¡å¤§å°: {batch_size}")
        
        for test_i in range(10):  # æ¯ä¸ªæ‰¹æ¬¡å¤§å°æµ‹è¯•10æ¬¡
            total_tests += 1
            
            # ç”Ÿæˆéšæœºè¾“å…¥
            test_input = torch.randn(batch_size, 11).to(device)
            
            try:
                # è·å–æ¨¡å‹å‚æ•°
                params_mean, params_logvar = get_bayesian_model_mu_rho(model)
                
                # è®¡ç®—Function KL
                function_kl = calculate_function_kl(
                    params_mean, params_logvar, test_input, model=model
                )
                
                # æ£€æŸ¥ç»“æœ
                if torch.isnan(function_kl) or torch.isinf(function_kl):
                    print(f"  æµ‹è¯• {test_i+1}: âœ— ç»“æœæ— æ•ˆ ({function_kl})")
                elif function_kl < 0:
                    print(f"  æµ‹è¯• {test_i+1}: âš  è´Ÿå€¼ ({function_kl:.6f})")
                    success_count += 0.5  # éƒ¨åˆ†æˆåŠŸ
                else:
                    print(f"  æµ‹è¯• {test_i+1}: âœ“ æˆåŠŸ ({function_kl:.6f})")
                    success_count += 1
                    
            except Exception as e:
                print(f"  æµ‹è¯• {test_i+1}: âœ— å¼‚å¸¸ - {str(e)[:50]}...")
    
    success_rate = success_count / total_tests * 100
    print(f"\næ€»ä½“æˆåŠŸç‡: {success_rate:.1f}% ({success_count}/{total_tests})")
    
    if success_rate > 80:
        print("ğŸ‰ Function KLè®¡ç®—ç¨³å®šæ€§æµ‹è¯•é€šè¿‡ï¼")
    elif success_rate > 50:
        print("âš ï¸  Function KLè®¡ç®—éƒ¨åˆ†ç¨³å®šï¼Œä½†ä»æœ‰æ”¹è¿›ç©ºé—´")
    else:
        print("âŒ Function KLè®¡ç®—ä»ç„¶ä¸ç¨³å®š")

def test_covariance_properties():
    """æµ‹è¯•åæ–¹å·®çŸ©é˜µçš„æ•°å­¦æ€§è´¨"""
    print("\n=== æµ‹è¯•åæ–¹å·®çŸ©é˜µæ•°å­¦æ€§è´¨ ===")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = SimpleBayesianModel().to(device)
    
    # å°æ‰¹æ¬¡æµ‹è¯•ï¼Œä¾¿äºæ£€æŸ¥
    test_input = torch.randn(8, 11).to(device)
    params_mean, params_logvar = get_bayesian_model_mu_rho(model)
    
    # å¯¼å…¥å†…éƒ¨å‡½æ•°è¿›è¡Œæµ‹è¯•
    from function_kl import calculate_moments
    
    try:
        # è®¡ç®—åæ–¹å·®çŸ©é˜µ
        _, cov_matrix = calculate_moments(model, params_mean, params_logvar, test_input)
        cov_2d = cov_matrix[:, :, 0]  # æå–2DçŸ©é˜µ
        
        print(f"åæ–¹å·®çŸ©é˜µå½¢çŠ¶: {cov_2d.shape}")
        print(f"åæ–¹å·®çŸ©é˜µå¯¹è§’çº¿æœ€å°å€¼: {torch.diag(cov_2d).min():.6f}")
        print(f"åæ–¹å·®çŸ©é˜µå¯¹è§’çº¿æœ€å¤§å€¼: {torch.diag(cov_2d).max():.6f}")
        
        # æ£€æŸ¥å¯¹ç§°æ€§
        is_symmetric = torch.allclose(cov_2d, cov_2d.t(), rtol=1e-5)
        print(f"çŸ©é˜µå¯¹ç§°æ€§: {'âœ“' if is_symmetric else 'âœ—'}")
        
        # æ£€æŸ¥æ­£å®šæ€§
        eigenvals = torch.linalg.eigvals(cov_2d).real
        min_eigenval = eigenvals.min()
        print(f"æœ€å°ç‰¹å¾å€¼: {min_eigenval:.6f}")
        print(f"æ­£å®šæ€§: {'âœ“' if min_eigenval > 1e-8 else 'âœ—'}")
        
        # å°è¯•Choleskyåˆ†è§£
        try:
            torch.linalg.cholesky(cov_2d)
            print("Choleskyåˆ†è§£: âœ“")
        except:
            print("Choleskyåˆ†è§£: âœ—")
            
    except Exception as e:
        print(f"åæ–¹å·®çŸ©é˜µè®¡ç®—å¤±è´¥: {e}")

if __name__ == "__main__":
    print("å¼€å§‹æµ‹è¯•ä¿®å¤åçš„Function KLè®¡ç®—...")
    print("=" * 50)
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    test_positive_definite_function()
    test_function_kl_stability()
    test_covariance_properties()
    
    print("\n" + "=" * 50)
    print("æµ‹è¯•å®Œæˆï¼") 