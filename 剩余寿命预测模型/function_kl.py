import torch
import torch.nn as nn
import torch.distributions as dist
from torch.distributions import MultivariateNormal, kl_divergence
import copy

# æ·»åŠ å¯è§†åŒ–åŠŸèƒ½çš„å¯¼å…¥
try:
    import matplotlib.pyplot as plt
    import numpy as np
    VISUALIZATION_AVAILABLE = True
except ImportError:
    VISUALIZATION_AVAILABLE = False
    print("Warning: matplotlibæœªå®‰è£…ï¼Œå¯è§†åŒ–åŠŸèƒ½ä¸å¯ç”¨")

def calculate_moments(model,params_mean, params_logvar, inputs, debug_nan=False):
    """
    æ ¹æ®è¾“å…¥çš„å‡å€¼å’Œæ–¹å·®ï¼Œå°†è¾“å…¥åˆ†å¸ƒè¿›è¡Œå±€éƒ¨çº¿æ€§åŒ–
    """
    if debug_nan:
        print("ğŸ” calculate_momentså¼€å§‹...")

    # æŠŠå‚æ•°å‡å€¼å’Œå‚æ•°å¯¹æ•°æ–¹å·®éƒ½æ‹†åˆ†ä¸ºç‰¹å¾å±‚å’Œè¾“å‡ºå±‚
    params_feature_mean, params_final_layer_mean = split_params(params_mean)
    params_feature_logvar, params_final_layer_logvar = split_params(params_logvar)
    
    if debug_nan:
        print(f"  ç‰¹å¾å±‚å‚æ•°æ•°é‡: {len(params_feature_mean)}")
        print(f"  è¾“å‡ºå±‚å‚æ•°æ•°é‡: {len(params_final_layer_mean)}")
        
        # æ£€æŸ¥è¾“å‡ºå±‚å‚æ•°
        for name, param in params_final_layer_logvar.items():
            if torch.isnan(param).any():
                print(f"âŒ è¾“å‡ºå±‚å‚æ•°åŒ…å«NaN: {name}")
            if torch.isinf(param).any():
                print(f"âš ï¸ è¾“å‡ºå±‚å‚æ•°åŒ…å«Inf: {name}, å€¼èŒƒå›´: [{param.min():.2f}, {param.max():.2f}]")
    
    # ä»ç‰¹å¾å‚æ•°çš„å‡å€¼å’Œå¯¹æ•°æ–¹å·®ä¸­é‡‡æ ·ä¸€ç»„å‚æ•°
    params_feature_sample = sample_parameters(params_feature_mean, params_feature_logvar)
    # å°†ä»ç‰¹å¾å‚æ•°é‡‡æ ·çš„å‚æ•°ä¸æœ€ç»ˆå±‚å‚æ•°çš„å‡å€¼åˆå¹¶ï¼Œä»¥è·å¾—å®Œæ•´çš„æ¨¡å‹å‚æ•°
    params_partial_sample = merge_params(params_feature_sample, params_final_layer_mean)
    # è·å¾—æ¨¡å‹è¾“å‡ºå’Œç‰¹å¾æ ·æœ¬

    # ä¿å­˜å½“å‰å‚æ•°
    original_state = {k: v.clone() for k, v in model.state_dict().items()}
    # åŠ è½½é‡‡æ ·å‚æ•°
    model.load_state_dict(params_partial_sample, strict=False)
    # é¢„æµ‹
    with torch.no_grad():
        # output = model(inputs)
        preds_f_sample, _, _, feature_sample = model(inputs, feature=True)
    # æ¢å¤åŸå‚æ•°
    model.load_state_dict(original_state)
    
    if debug_nan:
        print(f"  æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {preds_f_sample.shape}")
        print(f"  ç‰¹å¾æ ·æœ¬å½¢çŠ¶: {feature_sample.shape}")
        if torch.isnan(preds_f_sample).any():
            print("âŒ æ¨¡å‹è¾“å‡ºåŒ…å«NaN")
        if torch.isnan(feature_sample).any():
            print("âŒ ç‰¹å¾æ ·æœ¬åŒ…å«NaN")
    
    n_samples = preds_f_sample.shape[1]
    feature_dim = feature_sample.shape[1]
    
    # final_layer_var_weights,final_layer_var_biasåˆ†åˆ«æ˜¯æœ€ç»ˆå±‚æƒé‡å’Œåç½®é¡¹çš„å¯¹æ•°æ–¹å·®ï¼Œé€šè¿‡å–æŒ‡æ•°å¾—åˆ°çœŸå®æ–¹å·®
    # é‚£ä¹ˆsigma.rho_weightè¦ä¸è¦è€ƒè™‘è¿›å»å‘¢
    final_layer_var_weights = torch.exp(params_final_layer_logvar["mu.rho_weight"])
    final_layer_var_bias = torch.exp(params_final_layer_logvar["mu.rho_bias"])
    
    if debug_nan:
        print(f"  æœ€ç»ˆå±‚æƒé‡æ–¹å·®: min={final_layer_var_weights.min():.8f}, max={final_layer_var_weights.max():.8f}")
        print(f"  æœ€ç»ˆå±‚åç½®æ–¹å·®: min={final_layer_var_bias.min():.8f}, max={final_layer_var_bias.max():.8f}")
        
        if torch.isnan(final_layer_var_weights).any():
            print("âŒ æœ€ç»ˆå±‚æƒé‡æ–¹å·®åŒ…å«NaN")
        if torch.isnan(final_layer_var_bias).any():
            print("âŒ æœ€ç»ˆå±‚åç½®æ–¹å·®åŒ…å«NaN")
        if torch.isinf(final_layer_var_weights).any():
            print("âš ï¸ æœ€ç»ˆå±‚æƒé‡æ–¹å·®åŒ…å«Inf")
        if torch.isinf(final_layer_var_bias).any():
            print("âš ï¸ æœ€ç»ˆå±‚åç½®æ–¹å·®åŒ…å«Inf")

    # num_classes = 1
    # feature_times_var = (final_layer_var_weights.repeat(n_samples, 1).
    #                     reshape(n_samples, feature_dim, num_classes) * feature_sample[:, :,None]).permute(2, 0, 1)
    # preds_f_cov = torch.matmul(feature_times_var, feature_sample.T).permute(1, 2, 0)
    # preds_f_cov += preds_f_cov + final_layer_var_bias[None, None, :]
    
    # Step 1: é‡å¤ final_layer_var_weights n_samples æ¬¡ï¼Œå½¢çŠ¶å˜ä¸º (n_samples, feature_dim)
    repeated_weights = final_layer_var_weights.repeat(n_samples, 1)  # å½¢çŠ¶: (n_samples, feature_dim)
    
    # Step 2: é‡å¡‘ä¸º (n_samples, feature_dim, 1) ï¼ˆå› ä¸º self.num_classes=1ï¼‰
    reshaped_weights = repeated_weights.unsqueeze(-1)  # å½¢çŠ¶: (n_samples, feature_dim, 1)
    
    # Step 3: æ‰©å±• feature_sample å¢åŠ ä¸€ä¸ªç»´åº¦
    feature_sample_expanded = feature_sample.unsqueeze(-1)  # å½¢çŠ¶: (n_samples, feature_dim, 1)
    
    # Step 4: é€å…ƒç´ ç›¸ä¹˜
    feature_times_var = reshaped_weights * feature_sample_expanded  # å½¢çŠ¶: (n_samples, feature_dim, 1)
    
    # Step 5: è½¬ç½®ç»´åº¦ä¸º (1, n_samples, feature_dim)
    # ä½¿ç”¨ permute æ¥é‡æ–°æ’åˆ—ç»´åº¦
    feature_times_var_transposed = feature_times_var.permute(2, 0, 1)  # å½¢çŠ¶: (1, n_samples, feature_dim)
    
    # Step 6: çŸ©é˜µä¹˜æ³• feature_times_var_transposed (1, n_samples, feature_dim) ä¸ feature_sample.T (feature_dim, n_samples)
    # ç»“æœå½¢çŠ¶: (1, n_samples, n_samples)
    matmul_result = torch.matmul(feature_times_var_transposed, feature_sample.T)  # å½¢çŠ¶: (1, n_samples, n_samples)
    
    # Step 7: è½¬ç½®ç»“æœä¸º (n_samples, n_samples, 1)
    # ä½¿ç”¨ permute æ¥é‡æ–°æ’åˆ—ç»´åº¦
    preds_f_cov = matmul_result.permute(1, 2, 0)  # å½¢çŠ¶: (n_samples, n_samples, 1)
    
    # Step 8: æ·»åŠ  final_layer_var_bias
    # ç¡®ä¿ final_layer_var_bias è¢«æ‰©å±•ä¸º (1, 1, 1)
    if final_layer_var_bias.dim() == 0:
        # å¦‚æœ final_layer_var_bias æ˜¯æ ‡é‡ï¼Œæ‰©å±•ä¸º (1, 1, 1)
        final_layer_var_bias_expanded = final_layer_var_bias.unsqueeze(-1).unsqueeze(-1)  # å½¢çŠ¶: (1, 1, 1)
    else:
        # å¦‚æœ final_layer_var_bias å·²ç»æ˜¯ (self.num_classes,)ï¼Œå‡è®¾ self.num_classes=1
        final_layer_var_bias_expanded = final_layer_var_bias.unsqueeze(-1).unsqueeze(-1)  # å½¢çŠ¶: (1, 1, 1)
    
    if debug_nan:
        print(f"  åæ–¹å·®çŸ©é˜µè®¡ç®—å‰: å¯¹è§’çº¿min={torch.diag(preds_f_cov[:,:,0]).min():.8f}, max={torch.diag(preds_f_cov[:,:,0]).max():.8f}")
        if torch.isnan(preds_f_cov).any():
            print("âŒ åæ–¹å·®çŸ©é˜µè®¡ç®—è¿‡ç¨‹ä¸­å‡ºç°NaN")
    
    # å¹¿æ’­åŠ æ³•
    preds_f_cov = preds_f_cov + final_layer_var_bias_expanded  # å½¢çŠ¶: (n_samples, n_samples, 1)

    if debug_nan:
        print(f"  æœ€ç»ˆåæ–¹å·®çŸ©é˜µ: å¯¹è§’çº¿min={torch.diag(preds_f_cov[:,:,0]).min():.8f}, max={torch.diag(preds_f_cov[:,:,0]).max():.8f}")
        if torch.isnan(preds_f_cov).any():
            print("âŒ æœ€ç»ˆåæ–¹å·®çŸ©é˜µåŒ…å«NaN")
        print("âœ… calculate_momentså®Œæˆ")

    return preds_f_sample, preds_f_cov


def calculate_function_kl(
    inputs, 
    model,         # PyTorch æ¨¡å‹
    init_model,
    enable_diagnosis=False,    # æ˜¯å¦å¯ç”¨å¯è§†åŒ–è¯Šæ–­
    diagnosis_save_path="fkl.png",  # è¯Šæ–­å›¾ä¿å­˜è·¯å¾„
    diagnosis_threshold=1000,  # è§¦å‘è¯Šæ–­çš„KLé˜ˆå€¼
    debug_nan=True,  # å¯ç”¨NaNè°ƒè¯•
):
    """
    PyTorch å®ç°çš„å‡½æ•°ç©ºé—´ KL æ•£åº¦è®¡ç®—
    1.å‚æ•°åˆå§‹åŒ–â€‹â€‹ï¼šé€šè¿‡æ¨¡å‹åˆå§‹åŒ–æˆ–ç›´æ¥åŠ è½½é¢„å®šä¹‰å‚æ•°ï¼Œè®¾ç½®å…ˆéªŒåˆ†å¸ƒçš„å‡å€¼
    2.å…ˆéªŒæ–¹å·®è®¾ç½®â€‹â€‹ï¼šç‰¹å¾å±‚ä½¿ç”¨æå°å¯¹æ•°æ–¹å·®ï¼ˆå¼ºå…ˆéªŒçº¦æŸï¼‰ï¼Œæœ€ç»ˆå±‚ä½¿ç”¨è¾ƒå¤§å¯¹æ•°æ–¹å·®ï¼ˆå¼±çº¦æŸï¼‰
    3.åˆ†å¸ƒè®¡ç®—â€‹â€‹ï¼šåˆ†åˆ«è®¡ç®—å…ˆéªŒåˆ†å¸ƒå’Œå˜åˆ†åˆ†å¸ƒåœ¨å‡½æ•°ç©ºé—´çš„å‡å€¼å’Œåæ–¹å·®çŸ©é˜µ
    4.KLæ•£åº¦è®¡ç®—â€‹â€‹ï¼šé€šè¿‡è’™ç‰¹å¡æ´›é‡‡æ ·å¾—åˆ°çš„åˆ†å¸ƒæ ·æœ¬ï¼Œè®¡ç®—ä¸¤è€…ä¹‹é—´çš„KLæ•£åº¦
    
    Args:
        inputs: è¾“å…¥æ•°æ®
        model: å½“å‰è®­ç»ƒçš„æ¨¡å‹
        init_model: åˆå§‹æ¨¡å‹ï¼ˆå…ˆéªŒï¼‰
        enable_diagnosis: æ˜¯å¦å¯ç”¨å¯è§†åŒ–è¯Šæ–­
        diagnosis_save_path: è¯Šæ–­å›¾ä¿å­˜è·¯å¾„
        diagnosis_threshold: è§¦å‘è¯Šæ–­çš„KLé˜ˆå€¼
        debug_nan: å¯ç”¨NaNè°ƒè¯•
    """
    if debug_nan:
        print("ğŸ” Function KLè®¡ç®—å¼€å§‹ï¼Œå¯ç”¨NaNè°ƒè¯•...")
    
    try:
        model_copy = copy.deepcopy(model) # ç”¨æ¥å±€éƒ¨çº¿æ€§åŒ–
        
        '''åˆå§‹åŒ–å…ˆéªŒåˆ†å¸ƒ'''
        params_prior_mean, params_prior_logvar = get_bayesian_model_mu_rho(init_model)
        
        # æ£€æŸ¥å…ˆéªŒå‚æ•°æ˜¯å¦åŒ…å«NaN
        if debug_nan:
            for name, param in params_prior_mean.items():
                if torch.isnan(param).any():
                    print(f"âŒ æ£€æµ‹åˆ°å…ˆéªŒå‡å€¼NaN: {name}")
                    return torch.tensor(float('nan'))
            for name, param in params_prior_logvar.items():
                if torch.isnan(param).any():
                    print(f"âŒ æ£€æµ‹åˆ°å…ˆéªŒå¯¹æ•°æ–¹å·®NaN: {name}")
                    return torch.tensor(float('nan'))
        
        # è°ƒæ•´å…ˆéªŒæ–¹å·®è®¾ç½®ï¼Œé¿å…è¿‡äºæç«¯çš„å€¼
        feature_prior_logvar = -10  # ä»-20è°ƒæ•´åˆ°-10ï¼Œexp(-10) â‰ˆ 4.5e-5
        final_layer_prior_logvar = 1   # ä»-10è°ƒæ•´åˆ°1ï¼Œexp(1) â‰ˆ 2.718

        params_prior_logvar_init = {key: torch.zeros_like(value) for key,value in params_prior_logvar.items()}
        params_feature_prior_logvar_init, params_final_layer_prior_logvar_init = split_params(params_prior_logvar_init)
        params_feature_prior_logvar = {key: torch.zeros_like(value) + feature_prior_logvar for key,value in params_feature_prior_logvar_init.items()} 
        params_final_layer_prior_logvar = {key: torch.zeros_like(value) + final_layer_prior_logvar for key,value in params_final_layer_prior_logvar_init.items()}
        params_prior_logvar = merge_params(params_feature_prior_logvar, params_final_layer_prior_logvar)
        
        '''çº¿æ€§åŒ–å…ˆéªŒåˆ†å¸ƒ'''
        if debug_nan:
            print("ğŸ“Š è®¡ç®—å…ˆéªŒåˆ†å¸ƒmoments...")
        preds_f_prior_mean, preds_f_prior_cov = calculate_moments(model_copy, params_prior_mean, params_prior_logvar, inputs, debug_nan)
        
        # æ£€æŸ¥å…ˆéªŒåˆ†å¸ƒè®¡ç®—ç»“æœ
        if debug_nan:
            if torch.isnan(preds_f_prior_mean).any():
                print("âŒ å…ˆéªŒå‡å€¼åŒ…å«NaN")
                print(f"å…ˆéªŒå‡å€¼å½¢çŠ¶: {preds_f_prior_mean.shape}")
                print(f"å…ˆéªŒå‡å€¼ç»Ÿè®¡: min={preds_f_prior_mean.min():.6f}, max={preds_f_prior_mean.max():.6f}")
                return torch.tensor(float('nan'))
            if torch.isnan(preds_f_prior_cov).any():
                print("âŒ å…ˆéªŒåæ–¹å·®åŒ…å«NaN")
                print(f"å…ˆéªŒåæ–¹å·®å½¢çŠ¶: {preds_f_prior_cov.shape}")
                print(f"å…ˆéªŒåæ–¹å·®å¯¹è§’çº¿ç»Ÿè®¡: min={torch.diag(preds_f_prior_cov[:,:,0]).min():.6f}, max={torch.diag(preds_f_prior_cov[:,:,0]).max():.6f}")
                return torch.tensor(float('nan'))
            print(f"âœ… å…ˆéªŒåˆ†å¸ƒè®¡ç®—æ­£å¸¸: å‡å€¼={preds_f_prior_mean.mean():.6f}, åæ–¹å·®å¯¹è§’çº¿={torch.diag(preds_f_prior_cov[:,:,0]).mean():.6f}")

        '''çº¿æ€§åŒ–å˜åˆ†åˆ†å¸ƒ'''
        params_variational_mean, params_variational_logvar = get_bayesian_model_mu_rho(model)
        
        # æ£€æŸ¥å˜åˆ†å‚æ•°æ˜¯å¦åŒ…å«NaN
        if debug_nan:
            for name, param in params_variational_mean.items():
                if torch.isnan(param).any():
                    print(f"âŒ æ£€æµ‹åˆ°å˜åˆ†å‡å€¼NaN: {name}")
                    return torch.tensor(float('nan'))
            for name, param in params_variational_logvar.items():
                if torch.isnan(param).any():
                    print(f"âŒ æ£€æµ‹åˆ°å˜åˆ†å¯¹æ•°æ–¹å·®NaN: {name}")
                    return torch.tensor(float('nan'))
                if torch.isinf(param).any():
                    print(f"âš ï¸ æ£€æµ‹åˆ°å˜åˆ†å¯¹æ•°æ–¹å·®Inf: {name}, å€¼èŒƒå›´: [{param.min():.2f}, {param.max():.2f}]")
        
        if debug_nan:
            print("ğŸ“Š è®¡ç®—å˜åˆ†åˆ†å¸ƒmoments...")
        preds_f_variational_mean, preds_f_variational_cov = calculate_moments(model_copy, params_variational_mean, params_variational_logvar, inputs, debug_nan)
        
        # æ£€æŸ¥å˜åˆ†åˆ†å¸ƒè®¡ç®—ç»“æœ
        if debug_nan:
            if torch.isnan(preds_f_variational_mean).any():
                print("âŒ å˜åˆ†å‡å€¼åŒ…å«NaN")
                print(f"å˜åˆ†å‡å€¼å½¢çŠ¶: {preds_f_variational_mean.shape}")
                print(f"å˜åˆ†å‡å€¼ç»Ÿè®¡: min={preds_f_variational_mean.min():.6f}, max={preds_f_variational_mean.max():.6f}")
                return torch.tensor(float('nan'))
            if torch.isnan(preds_f_variational_cov).any():
                print("âŒ å˜åˆ†åæ–¹å·®åŒ…å«NaN")
                print(f"å˜åˆ†åæ–¹å·®å½¢çŠ¶: {preds_f_variational_cov.shape}")
                print(f"å˜åˆ†åæ–¹å·®å¯¹è§’çº¿ç»Ÿè®¡: min={torch.diag(preds_f_variational_cov[:,:,0]).min():.6f}, max={torch.diag(preds_f_variational_cov[:,:,0]).max():.6f}")
                return torch.tensor(float('nan'))
            print(f"âœ… å˜åˆ†åˆ†å¸ƒè®¡ç®—æ­£å¸¸: å‡å€¼={preds_f_variational_mean.mean():.6f}, åæ–¹å·®å¯¹è§’çº¿={torch.diag(preds_f_variational_cov[:,:,0]).mean():.6f}")
        
        # è®¡ç®—KLæ•£åº¦
        fkl = 0
        n_samples = preds_f_variational_mean.shape[0]
        cov_jitter = 1e-4  # å¢åŠ æŠ–åŠ¨é¡¹
        num_classes = 1
        device = preds_f_prior_cov.device
        
        if debug_nan:
            print(f"ğŸ“Š å¼€å§‹è®¡ç®—KLæ•£åº¦: n_samples={n_samples}, num_classes={num_classes}")
        
        for j in range(num_classes):
            # ä¿è¯ mean æ˜¯ä¸€ç»´ï¼Œcov æ˜¯äºŒç»´
            _preds_f_prior_mean = preds_f_prior_mean[:, j].reshape(-1)
            _preds_f_prior_cov = preds_f_prior_cov[:, :, j]

            _preds_f_variational_mean = preds_f_variational_mean[:, j].reshape(-1)
            _preds_f_variational_cov = preds_f_variational_cov[:, :, j]
            
            # ğŸ”§ å¼ºåŒ–åæ–¹å·®çŸ©é˜µæ­£å®šæ€§ä¿®æ­£
            _preds_f_prior_cov = ensure_positive_definite(_preds_f_prior_cov, min_eigenvalue=cov_jitter, debug=debug_nan, name="å…ˆéªŒ")
            _preds_f_variational_cov = ensure_positive_definite(_preds_f_variational_cov, min_eigenvalue=cov_jitter, debug=debug_nan, name="å˜åˆ†")
            
            # è¯¦ç»†çš„åæ–¹å·®çŸ©é˜µæ£€æŸ¥
            if debug_nan:
                print(f"ğŸ“Š ç±»åˆ« {j} åæ–¹å·®çŸ©é˜µæ£€æŸ¥:")
                
                # æ£€æŸ¥åæ–¹å·®çŸ©é˜µçš„æ•°å­¦æ€§è´¨
                prior_eigs = torch.linalg.eigvals(_preds_f_prior_cov).real
                var_eigs = torch.linalg.eigvals(_preds_f_variational_cov).real
                
                print(f"  å…ˆéªŒåæ–¹å·®: æœ€å°ç‰¹å¾å€¼={prior_eigs.min():.8f}, æœ€å¤§ç‰¹å¾å€¼={prior_eigs.max():.8f}")
                print(f"  å˜åˆ†åæ–¹å·®: æœ€å°ç‰¹å¾å€¼={var_eigs.min():.8f}, æœ€å¤§ç‰¹å¾å€¼={var_eigs.max():.8f}")
                
                # æ£€æŸ¥æ¡ä»¶æ•°
                prior_cond = torch.linalg.cond(_preds_f_prior_cov)
                var_cond = torch.linalg.cond(_preds_f_variational_cov)
                print(f"  åæ–¹å·®çŸ©é˜µæ¡ä»¶æ•°: å…ˆéªŒ={prior_cond:.2e}, å˜åˆ†={var_cond:.2e}")
                
                if prior_cond > 1e12 or var_cond > 1e12:
                    print("âš ï¸ åæ–¹å·®çŸ©é˜µæ¡ä»¶æ•°è¿‡å¤§ï¼Œå¯èƒ½å¯¼è‡´æ•°å€¼ä¸ç¨³å®š")

            try:
                # å°è¯•åˆ›å»ºå¤šå…ƒæ­£æ€åˆ†å¸ƒ
                q = MultivariateNormal(loc=_preds_f_variational_mean, covariance_matrix=_preds_f_variational_cov)
                p = MultivariateNormal(loc=_preds_f_prior_mean, covariance_matrix=_preds_f_prior_cov)
                
                if debug_nan:
                    print(f"âœ… æˆåŠŸåˆ›å»ºå¤šå…ƒæ­£æ€åˆ†å¸ƒ")
                
                # è®¡ç®—KLæ•£åº¦
                kl = kl_divergence(q, p)
                
                if debug_nan:
                    print(f"ğŸ“Š KLæ•£åº¦è®¡ç®—ç»“æœ: {kl.item():.6f}")
                
                # æ£€æŸ¥KLæ•£åº¦ç»“æœ
                if torch.isnan(kl):
                    print(f"âŒ KLæ•£åº¦è®¡ç®—å¾—åˆ°NaN!")
                    print(f"  å…ˆéªŒå‡å€¼: {_preds_f_prior_mean[:5]}")
                    print(f"  å˜åˆ†å‡å€¼: {_preds_f_variational_mean[:5]}")
                    print(f"  å…ˆéªŒåæ–¹å·®å¯¹è§’çº¿: {torch.diag(_preds_f_prior_cov)[:5]}")
                    print(f"  å˜åˆ†åæ–¹å·®å¯¹è§’çº¿: {torch.diag(_preds_f_variational_cov)[:5]}")
                    return torch.tensor(float('nan'))
                
                if torch.isinf(kl):
                    print(f"âŒ KLæ•£åº¦è®¡ç®—å¾—åˆ°Inf: {kl.item()}")
                    return torch.tensor(float('inf'))
                
                fkl = fkl + kl
                
            except Exception as e:
                pass
                # print(f"âŒ å¤šå…ƒæ­£æ€åˆ†å¸ƒæˆ–KLæ•£åº¦è®¡ç®—å¤±è´¥")
                # ä½œä¸ºæœ€åçš„å¤‡é€‰æ–¹æ¡ˆï¼Œä½¿ç”¨å‚æ•°ç©ºé—´KLè¿‘ä¼¼
                # print("ğŸ”„ å°è¯•ä½¿ç”¨å‚æ•°ç©ºé—´KLè¿‘ä¼¼...")
                # try:
                #     param_kl_approx = approximate_function_kl_with_parameter_kl(model, init_model)
                #     print(f"ğŸ“Š å‚æ•°ç©ºé—´KLè¿‘ä¼¼: {param_kl_approx:.6f}")
                #     return param_kl_approx
                # except:
                #     return torch.tensor(float('nan'))

        # æœ€ç»ˆæ£€æŸ¥
        if debug_nan:
            if torch.isnan(fkl):
                # print(f"âŒ æœ€ç»ˆFunction KLä¸ºNaN!")
                return fkl
            elif torch.isinf(fkl):
                # print(f"âš ï¸ æœ€ç»ˆFunction KLä¸ºInf: {fkl.item()}")
                return fkl
            else:
                print(f"âœ… Function KLè®¡ç®—å®Œæˆ: {fkl.item():.6f}")

        # å¯è§†åŒ–è¯Šæ–­åŠŸèƒ½
        if enable_diagnosis and (fkl.item() > diagnosis_threshold):
            print(f"âš ï¸  æ£€æµ‹åˆ°å¼‚å¸¸å¤§çš„Function KL: {fkl.item():.2f}, å¯åŠ¨è¯Šæ–­...")
            diagnosis_result = visualize_kl_diagnosis(
                model=model, 
                init_model=init_model, 
                inputs=inputs,
                function_kl_value=fkl.item(),
                save_path=diagnosis_save_path
            )
            if diagnosis_result:
                print("ğŸ“Š è¯Šæ–­å®Œæˆï¼Œè¯·æŸ¥çœ‹å¯è§†åŒ–ç»“æœ")
        elif enable_diagnosis:
            print(f"âœ… Function KLæ­£å¸¸: {fkl.item():.2f}")

        return fkl
        
    except Exception as e:
        # print(f"âŒ Function KLè®¡ç®—è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return torch.tensor(float('nan'))

def get_bayesian_model_parameters(model):
    """
    è·å– bayesian-torch ç¼–å†™çš„æ¨¡å‹çš„æ‰€æœ‰å‚æ•°ï¼ˆåŒ…æ‹¬å‡å€¼ã€æ–¹å·®ç­‰ï¼‰ï¼Œå¹¶å†»ç»“å‚æ•°çš„æ¢¯åº¦
    è¿”å›ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºå‚æ•°åï¼Œå€¼ä¸ºå‚æ•°çš„ tensorã€‚
    """
    params = {}
    for name, param in model.named_parameters():
        param.requires_grad = False
        params[name] = param.data.clone()
    return params

def get_bayesian_model_mu_rho(model):
    """
    ç”¨æ¥æ„é€ å˜åˆ†åˆ†å¸ƒ
    è·å–BayesianTCNæ¨¡å‹æ‰€æœ‰è´å¶æ–¯å±‚çš„å‚æ•°å‡å€¼(mu)å’Œå¯¹æ•°æ–¹å·®(rho)å­—å…¸
    è¿”å›ä¸¤ä¸ªå­—å…¸ï¼šmu_dict, rho_dict
    """
    mu_dict = {}
    rho_dict = {}
    for name, param in model.named_parameters():
        if 'mu_' in name:
            mu_dict[name] = param.data.clone()
        elif 'rho_' in name:
            rho_dict[name] = param.data.clone()
    return mu_dict, rho_dict

def get_bayesian_model_mu_rho_from_dict(params_dict):
    """
    ç”¨æ¥æ„é€ å…ˆéªŒåˆ†å¸ƒ
    ä»å‚æ•°å­—å…¸ä¸­æå–æ‰€æœ‰è´å¶æ–¯å±‚çš„å‚æ•°å‡å€¼(mu)å’Œå¯¹æ•°æ–¹å·®(rho)ï¼Œè¿”å›ä¸¤ä¸ªå­—å…¸ï¼šmu_dict, rho_dict
    """
    mu_dict = {}
    rho_dict = {}
    for name, param in params_dict.items():
        if 'mu_' in name:
            mu_dict[name] = param.clone()
        elif 'rho_' in name:
            rho_dict[name] = param.clone()
    return mu_dict, rho_dict

def split_params(params_dict):
    """æ‰‹åŠ¨æ‹†åˆ†å‚æ•°ä¸ºç‰¹å¾å±‚å’Œæœ€ç»ˆå±‚
    è¾“å‡ºå±‚å¿…é¡»æ˜¯åŒå¤´è¾“å‡ºçš„ï¼Œæ ‡è®°ä¸ºmuå’Œsigmaï¼Œå…¶ä»–å±‚ä¸ºç‰¹å¾å±‚
    """
    feature_params = {k: v for k, v in params_dict.items() if not (k.startswith('mu.') or k.startswith('sigma.'))}
    output_params = {k: v for k, v in params_dict.items() if k.startswith('mu.') or k.startswith('sigma.')}
    # print("output_params", output_params)
    return feature_params, output_params
 
def merge_params(params_1, params_2):
    """
    åˆå¹¶ä¸¤ä¸ªå‚æ•°å­—å…¸ï¼Œparams_2ä¸­çš„é”®ä¼šè¦†ç›–params_1ä¸­çš„åŒåé”®ã€‚
    """
    merged = params_1.copy()
    merged.update(params_2)
    return merged

def zeros_like_params(params_dict, delta=0.0):
    """
    æ ¹æ®ä¸€ä¸ªå‚æ•°å­—å…¸ï¼Œç”Ÿæˆä¸€ä¸ªç»“æ„å’Œå½¢çŠ¶å®Œå…¨ä¸€æ ·ã€ä½†æ•°å€¼å…¨ä¸º0çš„æ–°å­—å…¸ã€‚
    """
    return {k: torch.zeros_like(v) + delta for k, v in params_dict.items()}

def ensure_positive_definite(matrix, min_eigenvalue=1e-6, debug=False, name=""):
    """
    ç¡®ä¿åæ–¹å·®çŸ©é˜µæ­£å®š
    
    Args:
        matrix: è¾“å…¥åæ–¹å·®çŸ©é˜µ
        min_eigenvalue: æœ€å°ç‰¹å¾å€¼é˜ˆå€¼
        debug: æ˜¯å¦è¾“å‡ºè°ƒè¯•ä¿¡æ¯
        name: çŸ©é˜µåç§°ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    
    Returns:
        ä¿®æ­£åçš„æ­£å®šçŸ©é˜µ
    """
    try:
        # é¦–å…ˆç¡®ä¿çŸ©é˜µå¯¹ç§°
        matrix = (matrix + matrix.t()) / 2
        
        # è®¡ç®—ç‰¹å¾å€¼åˆ†è§£
        eigenvals, eigenvecs = torch.linalg.eigh(matrix)
        
        if debug and name:
            print(f"  ğŸ”§ {name}åæ–¹å·®çŸ©é˜µä¿®æ­£: åŸå§‹æœ€å°ç‰¹å¾å€¼={eigenvals.min():.8f}")
        
        # ä¿®æ­£è´Ÿç‰¹å¾å€¼å’Œè¿‡å°çš„ç‰¹å¾å€¼
        eigenvals_corrected = torch.clamp(eigenvals, min=min_eigenvalue)
        
        # é‡æ„çŸ©é˜µ
        matrix_corrected = eigenvecs @ torch.diag(eigenvals_corrected) @ eigenvecs.t()
        
        if debug and name:
            print(f"  âœ… {name}åæ–¹å·®çŸ©é˜µä¿®æ­£å®Œæˆ: æ–°æœ€å°ç‰¹å¾å€¼={eigenvals_corrected.min():.8f}")
        
        return matrix_corrected
        
    except Exception as e:
        if debug:
            print(f"  âŒ {name}åæ–¹å·®çŸ©é˜µä¿®æ­£å¤±è´¥: {e}")
        # å¤‡é€‰æ–¹æ¡ˆï¼šç›´æ¥æ·»åŠ å¯¹è§’æŠ–åŠ¨é¡¹
        device = matrix.device
        n = matrix.size(0)
        return matrix + torch.eye(n, device=device) * min_eigenvalue

def approximate_function_kl_with_parameter_kl(model, init_model):
    """
    å½“Function KLè®¡ç®—å¤±è´¥æ—¶ï¼Œä½¿ç”¨å‚æ•°ç©ºé—´KLè¿‘ä¼¼
    
    Args:
        model: å½“å‰æ¨¡å‹
        init_model: åˆå§‹æ¨¡å‹
    
    Returns:
        å‚æ•°ç©ºé—´KLæ•£åº¦è¿‘ä¼¼å€¼
    """
    var_mu, var_rho = get_bayesian_model_mu_rho(model)
    prior_mu, prior_rho = get_bayesian_model_mu_rho(init_model)
    
    total_kl = 0.0
    
    for name in var_mu.keys():
        if name in prior_mu:
            mu_var = var_mu[name].flatten()
            mu_prior = prior_mu[name].flatten()
            
            rho_name = name.replace('mu_', 'rho_')
            if rho_name in var_rho and rho_name in prior_rho:
                var_var = torch.exp(var_rho[rho_name]).flatten()
                var_prior = torch.exp(prior_rho[rho_name]).flatten()
                
                # å•å˜é‡é«˜æ–¯KLæ•£åº¦ï¼šKL(q||p) = 0.5 * (log(Ïƒ_pÂ²/Ïƒ_qÂ²) + Ïƒ_qÂ²/Ïƒ_pÂ² + (Î¼_q-Î¼_p)Â²/Ïƒ_pÂ² - 1)
                kl_layer = 0.5 * (
                    torch.log(var_prior / (var_var + 1e-8)) + 
                    var_var / (var_prior + 1e-8) + 
                    (mu_var - mu_prior).pow(2) / (var_prior + 1e-8) - 1
                ).sum()
                
                total_kl += kl_layer
    
    # ç¼©æ”¾å› å­ï¼Œä½¿å…¶ä¸Function KLé‡çº§ç›¸è¿‘
    scale_factor = 0.1
    return total_kl * scale_factor

def sample_parameters(params_mu, params_logvar):
    """
    æ ¹æ®å‡å€¼å’Œå¯¹æ•°æ–¹å·®å‚æ•°å­—å…¸ï¼Œé‡‡æ ·ä¸€ç»„BNNå‚æ•°
    """
    sampled_params = {}
    for k in params_mu:
        # å°† mu çš„ key æ›¿æ¢æˆ rho çš„ key
        # print("k", k)
        rho_key = k.replace('mu_', 'rho_')
        if rho_key not in params_logvar:
            raise KeyError(f"{rho_key} not found in params_rho")
        mu = params_mu[k]
        rho = params_logvar[rho_key]
        # print("sample_parameters rho", rho)
        std = torch.exp(rho)  # æˆ– softplus(rho)ï¼Œè§†ä½ çš„å®ç°
        eps = torch.randn_like(std)
        sampled_params[k] = mu + std * eps
    return sampled_params

def visualize_kl_diagnosis(model, init_model, inputs, function_kl_value, save_path=None):
    """
    åœ¨function_klè®¡ç®—è¿‡ç¨‹ä¸­è¿›è¡Œå¯è§†åŒ–è¯Šæ–­
    
    Args:
        model: å½“å‰æ¨¡å‹
        init_model: åˆå§‹æ¨¡å‹
        inputs: è¾“å…¥æ•°æ®
        function_kl_value: è®¡ç®—å¾—åˆ°çš„Function KLå€¼
        save_path: ä¿å­˜è·¯å¾„
    """
    if not VISUALIZATION_AVAILABLE:
        print("å¯è§†åŒ–åŠŸèƒ½ä¸å¯ç”¨ï¼Œè·³è¿‡è¯Šæ–­")
        return None
    
    try:
        # è·å–å‚æ•°åˆ†å¸ƒ
        var_mu, var_rho = get_bayesian_model_mu_rho(model)
        prior_mu, prior_rho = get_bayesian_model_mu_rho(init_model)
        
        # è®¡ç®—ä¸€äº›å…³é”®ç»Ÿè®¡é‡
        var_mu_values = torch.cat([v.flatten() for v in var_mu.values()]).cpu().numpy()
        prior_mu_values = torch.cat([v.flatten() for v in prior_mu.values()]).cpu().numpy()
        var_variance = torch.cat([torch.exp(v).flatten() for v in var_rho.values()]).cpu().numpy()
        prior_variance = torch.cat([torch.exp(v).flatten() for v in prior_rho.values()]).cpu().numpy()
        
        # åˆ›å»ºç®€åŒ–çš„å¯è§†åŒ–
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        fig.suptitle(f'Function KL Diagnosis (KL={function_kl_value:.2f})', fontsize=14, fontweight='bold')
        
        # 1. å‚æ•°å‡å€¼åˆ†å¸ƒ
        ax = axes[0, 0]
        ax.hist(prior_mu_values, bins=30, alpha=0.7, label='Prior Mean', color='blue', density=True)
        ax.hist(var_mu_values, bins=30, alpha=0.7, label='Variational Mean', color='red', density=True)
        ax.set_title('Parameter Mean Distribution')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 2. å‚æ•°æ–¹å·®åˆ†å¸ƒï¼ˆå¯¹æ•°å°ºåº¦ï¼‰
        ax = axes[0, 1]
        ax.hist(np.log10(prior_variance + 1e-8), bins=30, alpha=0.7, label='Prior Variance(log)', color='blue', density=True)
        ax.hist(np.log10(var_variance + 1e-8), bins=30, alpha=0.7, label='Variational Variance(log)', color='red', density=True)
        ax.set_title('Parameter Variance Distribution(log10)')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 3. å‚æ•°åç§»åˆ†æ
        ax = axes[1, 0]
        param_diff = var_mu_values - prior_mu_values[:len(var_mu_values)]
        ax.hist(param_diff, bins=30, alpha=0.7, color='green', density=True)
        ax.axvline(np.mean(param_diff), color='red', linestyle='--', linewidth=2, 
                   label=f'Mean Shift={np.mean(param_diff):.4f}')
        ax.set_title('Parameter Shift Analysis')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 4. å…³é”®ç»Ÿè®¡ä¿¡æ¯
        ax = axes[1, 1]
        ax.axis('off')
        
        # è®¡ç®—å…³é”®ç»Ÿè®¡
        var_ratio = np.mean(var_variance) / np.mean(prior_variance)
        param_shift = np.std(param_diff)
        
        stats_text = f"""
KL Divergence Diagnosis Report:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Function KL: {function_kl_value:.2f}
Parameter Mean Shift: {np.mean(param_diff):.6f}
Parameter Shift Std: {param_shift:.6f}
Variance Ratio: {var_ratio:.3f}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Diagnosis Results:
"""
        
        if function_kl_value > 1000:
            stats_text += "âš ï¸ KL divergence too large!\n"
        if var_ratio > 5 or var_ratio < 0.2:
            stats_text += f"âš ï¸ Abnormal variance ratio: {var_ratio:.2f}\n"
        if param_shift > 0.1:
            stats_text += f"âš ï¸ Parameter shift too large: {param_shift:.4f}\n"
            
        if function_kl_value < 100 and 0.2 <= var_ratio <= 5 and param_shift <= 0.1:
            stats_text += "âœ… Distribution status normal"
        
        ax.text(0.05, 0.95, stats_text, transform=ax.transAxes, fontsize=10,
                verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"KL diagnosis figure saved: {save_path}")
        
        plt.show()
        
        # è¿”å›è¯Šæ–­ä¿¡æ¯
        return {
            'function_kl': function_kl_value,
            'param_shift_mean': np.mean(param_diff),
            'param_shift_std': param_shift,
            'variance_ratio': var_ratio,
            'diagnosis': 'normal' if function_kl_value < 100 else 'abnormal'
        }
        
    except Exception as e:
        print(f"Visualization diagnosis failed: {e}")
        return None

def diagnose_kl_issues(model, init_model, context_inputs, save_prefix="kl_diagnosis"):
    """
    ä¾¿æ·çš„KLæ•£åº¦é—®é¢˜è¯Šæ–­å‡½æ•°
    
    Args:
        model: å½“å‰è®­ç»ƒçš„æ¨¡å‹
        init_model: åˆå§‹æ¨¡å‹ï¼ˆå…ˆéªŒï¼‰
        context_inputs: ä¸Šä¸‹æ–‡è¾“å…¥æ•°æ®
        save_prefix: ä¿å­˜æ–‡ä»¶çš„å‰ç¼€
    
    Returns:
        dict: åŒ…å«è¯Šæ–­ç»“æœçš„å­—å…¸
    """
    print("ğŸ” Starting KL divergence issue diagnosis...")
    
    # 1. è®¡ç®—Function KLå¹¶è‡ªåŠ¨è¯Šæ–­
    try:
        function_kl = calculate_function_kl(
            inputs=context_inputs,
            model=model,
            init_model=init_model,
            enable_diagnosis=True,
            diagnosis_save_path=f"{save_prefix}_function_kl.png",
            diagnosis_threshold=100  # é™ä½é˜ˆå€¼ï¼Œæ›´å®¹æ˜“è§¦å‘è¯Šæ–­
        )
        
        print(f"ğŸ“Š Function KL calculation completed: {function_kl.item():.2f}")
        
    except Exception as e:
        print(f"âŒ Function KL calculation failed: {e}")
        function_kl = torch.tensor(float('inf'))
    
    # 2. è¿›è¡Œå‚æ•°ç©ºé—´åˆ†æ
    try:
        var_mu, var_rho = get_bayesian_model_mu_rho(model)
        prior_mu, prior_rho = get_bayesian_model_mu_rho(init_model)
        
        # è®¡ç®—å‚æ•°ç»Ÿè®¡
        var_mu_values = torch.cat([v.flatten() for v in var_mu.values()]).cpu().numpy()
        prior_mu_values = torch.cat([v.flatten() for v in prior_mu.values()]).cpu().numpy()
        var_variance = torch.cat([torch.exp(v).flatten() for v in var_rho.values()]).cpu().numpy()
        prior_variance = torch.cat([torch.exp(v).flatten() for v in prior_rho.values()]).cpu().numpy()
        
        param_diff = var_mu_values - prior_mu_values[:len(var_mu_values)]
        
        # å‚æ•°ç©ºé—´KLè¿‘ä¼¼
        param_kl = 0
        for name in var_mu.keys():
            if name in prior_mu:
                mu_var = var_mu[name].flatten()
                mu_prior = prior_mu[name].flatten()
                
                rho_name = name.replace('mu_', 'rho_')
                if rho_name in var_rho and rho_name in prior_rho:
                    var_var = torch.exp(var_rho[rho_name]).flatten()
                    var_prior = torch.exp(prior_rho[rho_name]).flatten()
                    
                    # å•å˜é‡é«˜æ–¯KLæ•£åº¦
                    kl_layer = 0.5 * (
                        torch.log(var_prior / var_var) + 
                        var_var / var_prior + 
                        (mu_var - mu_prior).pow(2) / var_prior - 1
                    ).sum().item()
                    param_kl += kl_layer
        
        diagnosis_result = {
            'function_kl': function_kl.item() if torch.isfinite(function_kl) else float('inf'),
            'param_kl_approx': param_kl,
            'param_shift_mean': np.mean(param_diff),
            'param_shift_std': np.std(param_diff),
            'variance_ratio': np.mean(var_variance) / np.mean(prior_variance),
            'prior_var_mean': np.mean(prior_variance),
            'current_var_mean': np.mean(var_variance),
            'total_params': len(var_mu_values),
        }
        
        # 3. æ‰“å°è¯Šæ–­æŠ¥å‘Š
        print("\n" + "="*50)
        print("ğŸ“‹ KL Divergence Diagnosis Report")
        print("="*50)
        print(f"Function KL divergence:     {diagnosis_result['function_kl']:.2f}")
        print(f"Parameter space KL approx:  {diagnosis_result['param_kl_approx']:.2f}")
        print(f"Parameter mean shift:       {diagnosis_result['param_shift_mean']:.6f}")
        print(f"Parameter shift std:        {diagnosis_result['param_shift_std']:.6f}")
        print(f"Variance ratio:             {diagnosis_result['variance_ratio']:.3f}")
        print(f"Prior average variance:     {diagnosis_result['prior_var_mean']:.6f}")
        print(f"Current average variance:   {diagnosis_result['current_var_mean']:.6f}")
        print(f"Total parameter count:      {diagnosis_result['total_params']}")
        
        # 4. é—®é¢˜è¯Šæ–­å’Œå»ºè®®
        print("\n" + "-"*50)
        print("ğŸ”§ Problem Diagnosis and Suggestions:")
        print("-"*50)
        
        if diagnosis_result['function_kl'] > 1000:
            print("â— Function KLæ•£åº¦è¿‡å¤§ (>1000)")
            print("   å»ºè®®: ä½¿ç”¨å‚æ•°ç©ºé—´KLæ›¿ä»£ï¼Œæˆ–æ·»åŠ KLè£å‰ª")
        
        if diagnosis_result['param_kl_approx'] > 500:
            print("â— å‚æ•°ç©ºé—´KLæ•£åº¦è¿‡å¤§ (>500)")
            print("   å»ºè®®: å‡å°å­¦ä¹ ç‡ï¼Œå¢åŠ KLæƒé‡warm-up")
            
        if diagnosis_result['variance_ratio'] > 5:
            print("â— æ–¹å·®å¢é•¿è¿‡å¿« (>5å€)")
            print("   å»ºè®®: æ£€æŸ¥rhoåˆå§‹åŒ–ï¼Œé™ä½å­¦ä¹ ç‡")
        elif diagnosis_result['variance_ratio'] < 0.2:
            print("â— æ–¹å·®è¡°å‡è¿‡å¿« (<0.2å€)")
            print("   å»ºè®®: å¢åŠ å­¦ä¹ ç‡ï¼Œæ£€æŸ¥KLæƒé‡æ˜¯å¦è¿‡å¤§")
            
        if abs(diagnosis_result['param_shift_mean']) > 0.1:
            print(f"â— å‚æ•°å‡å€¼åç§»è¿‡å¤§ ({diagnosis_result['param_shift_mean']:.4f})")
            print("   å»ºè®®: æ£€æŸ¥æ¢¯åº¦è£å‰ªï¼Œé™ä½å­¦ä¹ ç‡")
            
        if diagnosis_result['param_shift_std'] > 0.5:
            print(f"â— å‚æ•°åç§»ä¸ä¸€è‡´ (std={diagnosis_result['param_shift_std']:.4f})")
            print("   å»ºè®®: æ£€æŸ¥ä¸åŒå±‚çš„å­¦ä¹ ç‡è®¾ç½®")
        
        # 5. å¦‚æœä¸€åˆ‡æ­£å¸¸
        if (diagnosis_result['function_kl'] < 100 and 
            diagnosis_result['param_kl_approx'] < 500 and
            0.2 <= diagnosis_result['variance_ratio'] <= 5 and
            abs(diagnosis_result['param_shift_mean']) <= 0.1):
            print("âœ… æ‰€æœ‰æŒ‡æ ‡æ­£å¸¸ï¼Œæ¨¡å‹è®­ç»ƒçŠ¶æ€è‰¯å¥½")
        
        print("="*50)
        
        return diagnosis_result
        
    except Exception as e:
        print(f"âŒ å‚æ•°åˆ†æå¤±è´¥: {e}")
        return {'error': str(e), 'function_kl': function_kl.item() if torch.isfinite(function_kl) else float('inf')}

# æ·»åŠ å¿«é€Ÿè¯Šæ–­å…¥å£
def quick_kl_check(model, init_model, context_inputs):
    """
    å¿«é€ŸKLæ£€æŸ¥ï¼Œåªæ‰“å°å…³é”®ä¿¡æ¯
    """
    try:
        fkl = calculate_function_kl(context_inputs, model, init_model)
        var_mu, var_rho = get_bayesian_model_mu_rho(model)
        prior_mu, prior_rho = get_bayesian_model_mu_rho(init_model)
        
        var_values = torch.cat([torch.exp(v).flatten() for v in var_rho.values()]).cpu().numpy()
        prior_values = torch.cat([torch.exp(v).flatten() for v in prior_rho.values()]).cpu().numpy()
        var_ratio = np.mean(var_values) / np.mean(prior_values)
        
        status = "ğŸŸ¢ æ­£å¸¸" if fkl.item() < 100 else "ğŸ”´ å¼‚å¸¸" if fkl.item() > 1000 else "ğŸŸ¡ è­¦å‘Š"
        print(f"KLå¿«æ£€: {status} | Function KL: {fkl.item():.1f} | æ–¹å·®æ¯”ä¾‹: {var_ratio:.2f}")
        
        return fkl.item()
    except Exception as e:
        print(f"KLå¿«æ£€å¤±è´¥: {e}")
        return float('inf')

def calculate_function_kl_robust(
    inputs, 
    model, 
    init_model,
    feature_prior_logvar=-10,      # å¯é…ç½®çš„ç‰¹å¾å±‚å…ˆéªŒå¯¹æ•°æ–¹å·®
    final_layer_prior_logvar=-5,   # å¯é…ç½®çš„è¾“å‡ºå±‚å…ˆéªŒå¯¹æ•°æ–¹å·®
    cov_jitter=1e-4,               # å¯é…ç½®çš„åæ–¹å·®æŠ–åŠ¨é¡¹
    use_parameter_kl_fallback=True, # æ˜¯å¦ä½¿ç”¨å‚æ•°ç©ºé—´KLä½œä¸ºåå¤‡
    enable_diagnosis=False,
    debug_nan=False
):
    """
    ç¨³å¥çš„Function KLè®¡ç®—å‡½æ•°ï¼Œæ”¯æŒå‚æ•°é…ç½®
    
    Args:
        inputs: è¾“å…¥æ•°æ®
        model: å½“å‰æ¨¡å‹
        init_model: åˆå§‹æ¨¡å‹
        feature_prior_logvar: ç‰¹å¾å±‚å…ˆéªŒå¯¹æ•°æ–¹å·®
        final_layer_prior_logvar: è¾“å‡ºå±‚å…ˆéªŒå¯¹æ•°æ–¹å·®
        cov_jitter: åæ–¹å·®çŸ©é˜µæŠ–åŠ¨é¡¹
        use_parameter_kl_fallback: æ˜¯å¦ä½¿ç”¨å‚æ•°KLä½œä¸ºåå¤‡
        enable_diagnosis: æ˜¯å¦å¯ç”¨è¯Šæ–­
        debug_nan: æ˜¯å¦å¯ç”¨NaNè°ƒè¯•
    
    Returns:
        Function KLæ•£åº¦å€¼
    """
    if debug_nan:
        print("ğŸ” ç¨³å¥Function KLè®¡ç®—å¼€å§‹...")
    
    try:
        model_copy = copy.deepcopy(model)
        
        '''åˆå§‹åŒ–å…ˆéªŒåˆ†å¸ƒ'''
        params_prior_mean, params_prior_logvar = get_bayesian_model_mu_rho(init_model)
        
        # ä½¿ç”¨å¯é…ç½®çš„å…ˆéªŒæ–¹å·®
        params_prior_logvar_init = {key: torch.zeros_like(value) for key,value in params_prior_logvar.items()}
        params_feature_prior_logvar_init, params_final_layer_prior_logvar_init = split_params(params_prior_logvar_init)
        params_feature_prior_logvar = {key: torch.zeros_like(value) + feature_prior_logvar for key,value in params_feature_prior_logvar_init.items()} 
        params_final_layer_prior_logvar = {key: torch.zeros_like(value) + final_layer_prior_logvar for key,value in params_final_layer_prior_logvar_init.items()}
        params_prior_logvar = merge_params(params_feature_prior_logvar, params_final_layer_prior_logvar)
        
        '''è®¡ç®—åˆ†å¸ƒ'''
        preds_f_prior_mean, preds_f_prior_cov = calculate_moments(model_copy, params_prior_mean, params_prior_logvar, inputs, debug_nan)
        
        params_variational_mean, params_variational_logvar = get_bayesian_model_mu_rho(model)
        preds_f_variational_mean, preds_f_variational_cov = calculate_moments(model_copy, params_variational_mean, params_variational_logvar, inputs, debug_nan)
        
        # è®¡ç®—KLæ•£åº¦
        fkl = 0
        n_samples = preds_f_variational_mean.shape[0]
        num_classes = 1
        device = preds_f_prior_cov.device
        
        for j in range(num_classes):
            _preds_f_prior_mean = preds_f_prior_mean[:, j].reshape(-1)
            _preds_f_prior_cov = preds_f_prior_cov[:, :, j]

            _preds_f_variational_mean = preds_f_variational_mean[:, j].reshape(-1)
            _preds_f_variational_cov = preds_f_variational_cov[:, :, j]
            
            # ç¡®ä¿åæ–¹å·®çŸ©é˜µæ­£å®š
            _preds_f_prior_cov = ensure_positive_definite(_preds_f_prior_cov, min_eigenvalue=cov_jitter, debug=debug_nan, name="å…ˆéªŒ")
            _preds_f_variational_cov = ensure_positive_definite(_preds_f_variational_cov, min_eigenvalue=cov_jitter, debug=debug_nan, name="å˜åˆ†")
            
            try:
                q = MultivariateNormal(loc=_preds_f_variational_mean, covariance_matrix=_preds_f_variational_cov)
                p = MultivariateNormal(loc=_preds_f_prior_mean, covariance_matrix=_preds_f_prior_cov)
                kl = kl_divergence(q, p)
                
                if torch.isnan(kl) or torch.isinf(kl):
                    raise ValueError(f"KL divergenceè®¡ç®—å¼‚å¸¸: {kl}")
                
                fkl = fkl + kl
                
            except Exception as e:
                if debug_nan:
                    # print(f"âŒ å¤šå…ƒæ­£æ€åˆ†å¸ƒKLè®¡ç®—å¤±è´¥: {e}")
                    pass
                if use_parameter_kl_fallback:
                    if debug_nan:
                        print("ğŸ”„ ä½¿ç”¨å‚æ•°ç©ºé—´KLè¿‘ä¼¼...")
                    return approximate_function_kl_with_parameter_kl(model, init_model)
                else:
                    return torch.tensor(float('nan'))
        
        if debug_nan:
            print(f"âœ… ç¨³å¥Function KLè®¡ç®—å®Œæˆ: {fkl.item():.6f}")
        
        return fkl
        
    except Exception as e:
        if debug_nan:
            print(f"âŒ ç¨³å¥Function KLè®¡ç®—å¤±è´¥: {e}")
        
        if use_parameter_kl_fallback:
            if debug_nan:
                print("ğŸ”„ æœ€ç»ˆä½¿ç”¨å‚æ•°ç©ºé—´KLè¿‘ä¼¼...")
            return approximate_function_kl_with_parameter_kl(model, init_model)
        else:
            return torch.tensor(float('nan'))

# ä¾¿æ·çš„é…ç½®é¢„è®¾
def get_function_kl_config(stability_level="medium"):
    """
    è·å–ä¸åŒç¨³å®šæ€§çº§åˆ«çš„Function KLé…ç½®
    
    Args:
        stability_level: "low", "medium", "high", "ultra"
    
    Returns:
        é…ç½®å­—å…¸
    """
    configs = {
        "low": {
            "feature_prior_logvar": -15,
            "final_layer_prior_logvar": -8,
            "cov_jitter": 1e-6,
            "use_parameter_kl_fallback": False
        },
        "medium": {
            "feature_prior_logvar": -10,
            "final_layer_prior_logvar": -5,
            "cov_jitter": 1e-4,
            "use_parameter_kl_fallback": True
        },
        "high": {
            "feature_prior_logvar": -8,
            "final_layer_prior_logvar": -3,
            "cov_jitter": 1e-3,
            "use_parameter_kl_fallback": True
        },
        "ultra": {
            "feature_prior_logvar": -5,
            "final_layer_prior_logvar": -2,
            "cov_jitter": 1e-2,
            "use_parameter_kl_fallback": True
        }
    }
    return configs.get(stability_level, configs["medium"])